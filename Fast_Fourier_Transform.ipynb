{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Numpy Fast Fourier Transform",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanMarcelKezmann/Fast-Fourier-Transformation-with-Python-and-Numpy/blob/master/Fast_Fourier_Transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSPBQiU_74h",
        "colab_type": "text"
      },
      "source": [
        "# Numpy Fast Fourier Transformation Implentation\n",
        "\n",
        "<p>In this short tutorial I am going to implement a Fast Fourier Transformation by using the Library <strong>Numpy</strong>.</p>\n",
        "<p>It is going to start of with a implementation of the FFT as well as the iFFT (inverse FFT) for arrays and will continue with the implementation of the FFT (and iFFT) for matrices.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVcC_R73_R73",
        "colab_type": "text"
      },
      "source": [
        "## Load the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BedYIkf_-gZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DxyjqcJ_V1f",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data\n",
        "\n",
        "<p>For this code example the mnist dataset for Machine Learning will be used to calculate the FFT2D as well as the iFFT2D of a single digit.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akIynqVj-35A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, _), (_, _) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE5AAPVuAXnd",
        "colab_type": "text"
      },
      "source": [
        "<p>Initialize function for image showing</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJlwxBX_Iv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_img(img, size=28):\n",
        "    img = img.reshape(size, size)\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YJEnrFgB-Fc",
        "colab_type": "text"
      },
      "source": [
        "<p>Let's start by defining an random array and by transforming it via the np.fft.fft function of the Numpy library. The FFT which we get from numpy serves as a comparison for the later on self-calculated FFT.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y8-k09sBxoA",
        "colab_type": "code",
        "outputId": "fbffcf63-ac9c-4b19-ab14-5e6a3f0bb44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# define a random array to transform over\n",
        "array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])\n",
        "\n",
        "np_fft_array = np.fft.fft(array)\n",
        "print(np_fft_array)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[136. +0.j          -8.+40.21871594j  -8.+19.3137085j   -8.+11.9728461j\n",
            "  -8. +8.j          -8. +5.3454291j   -8. +3.3137085j   -8. +1.59129894j\n",
            "  -8. +0.j          -8. -1.59129894j  -8. -3.3137085j   -8. -5.3454291j\n",
            "  -8. -8.j          -8.-11.9728461j   -8.-19.3137085j   -8.-40.21871594j]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUcfuu8ICtY6",
        "colab_type": "text"
      },
      "source": [
        "<p>Now it is time to implent the FFT by hand.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyar8Gx1Cz-Y",
        "colab_type": "text"
      },
      "source": [
        "## FFT\n",
        "### The Cooley-Tukey Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVMDrDHoGBRa",
        "colab_type": "text"
      },
      "source": [
        "<p>To implement the FFT the Cooley-Tukey algorithm will be used. Next to this only some minor changes are made which does not effect the algorithms performance, it only saves memory.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG8_e-Nh_xjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a function that bit reverse the input\n",
        "# per definition of the cooley-tukey algorithm this is necessary to get the\n",
        "# calculations in the fft into the correct order\n",
        "def bitrevorder(x):\n",
        "    len_max_bin = int(np.log2(len(x)))\n",
        "    if len_max_bin < 10:\n",
        "        helper = \"{0:0\" + str(len_max_bin) + \"b}\"\n",
        "    else:\n",
        "        helper = \"{0:\" + str(len_max_bin) + \"b}\"\n",
        "    # binarize array\n",
        "    str_x_bin = [helper.format(i) for i in range(len(x))]\n",
        "    # reverse each string in array\n",
        "    rev_str_x_bin = [i[::-1] for i in str_x_bin]\n",
        "    # get reversed indices of array\n",
        "    x_bro_ind = [int(i, 2) for i in rev_str_x_bin]\n",
        "    # get reversed numbers of array\n",
        "    x_bro = [x[i] for i in x_bro_ind]\n",
        "    return x_bro\n",
        "\n",
        "# FFT implentation\n",
        "\n",
        "############################################################################################\n",
        "    # Input:\n",
        "    #     a:              Input array which will be transformed\n",
        "    #     print_info:     Boolean. If set to True all calculation steps will be printed out\n",
        "    #     out_round_acc:  Integer. Define rounding accuracy\n",
        "    # Output:\n",
        "    #     rev_a:          FFT of the input array, same dimension as input array\n",
        "############################################################################################\n",
        "\n",
        "def fft(a, print_info=False, out_round_acc=6):\n",
        "    # bitreverse the input array to bring calculations in the for loops into the correct order\n",
        "    rev_a = bitrevorder(a)\n",
        "\n",
        "    n = int(np.log2(len(a)))\n",
        "\n",
        "    # Calculate the number of steps taken to compare it to the wanted running time of O(N * log(N))\n",
        "    # with N = len(a)\n",
        "    number_of_operations = 0\n",
        "    \n",
        "    for m  in range(1, n + 1):\n",
        "        if print_info:\n",
        "            print(\"m : \" + str(m))\n",
        "        for j in range(0, 2**(m - 1)):\n",
        "            e = round(np.exp(-2 * np.pi * complex(0, 1) * j / (2**m)), 8)\n",
        "            if print_info:\n",
        "                print(\"j : \" + str(j))\n",
        "            for r in range(0, (2**n), (2**m)):\n",
        "                v = rev_a[r + j + 2**(m - 1)] * e\n",
        "\n",
        "                rev_a[r + j + 2**(m - 1)] = rev_a[r + j] - v\n",
        "                rev_a[r + j] = rev_a[r + j] + v\n",
        "\n",
        "                if print_info:\n",
        "                    print(\"r : \" + str(r))\n",
        "                    print(\"Calculation of: beta[\" + str(r + j) + \"]\")\n",
        "                    print(\"BCalculation of: beta[\" + str(r + j + 2**(m - 1)) + \"]\")\n",
        "\n",
        "                # adapt the number of calculations\n",
        "                number_of_operations += 2\n",
        "\n",
        "    print(\"\\nN = \" + str(len(a)) + \" and Number of operations: (N * log_2(N)) = \" + str(number_of_operations) + \"\\n\")        \n",
        "    rev_a = [round(i, out_round_acc) for i in rev_a]\n",
        "    return rev_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXMJEsfbEty1",
        "colab_type": "code",
        "outputId": "06fe2750-afa1-443a-e05b-5b0f566db5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "fft_array = fft(array, print_info=False)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "N = 16 and Number of operations: (N * log_2(N)) = 64\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU0ygbnwFzOk",
        "colab_type": "text"
      },
      "source": [
        "<p>Now we can test if the self implemented version of the cooley-tukey algorithm is getting us the same result as the correct numpy comparison.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZLh0e70E0DC",
        "colab_type": "code",
        "outputId": "2ce837f8-efe8-41f8-aaa0-98af497aeb01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if implementation is close to the numpy solution\n",
        "print(np.isclose(np_fft_array, fft_array, rtol=1e-05, atol=1e-08))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-GvUyDcHIZ1",
        "colab_type": "text"
      },
      "source": [
        "<p>So, we know now that the algorithm is working fine.</p>\n",
        "<p>This means we can implement the inverse FFT now, which is if you ones have the FFT very trivial. It is only necessary to change the variable <strong>e</strong> and to remember that the result will contain only an array of real numbers and not complext ones.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXzXj0FRFBAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inverse FFT\n",
        "############################################################################################\n",
        "    # Input:\n",
        "    #     a:              Input array which will be retransformed\n",
        "    #     print_info:     Boolean. If set to True all calculation steps will be printed out\n",
        "    #     out_round_acc:  Integer. Define rounding accuracy\n",
        "    # Output:\n",
        "    #     rev_a:          iFFT of the input array, same dimension as input array\n",
        "############################################################################################\n",
        "\n",
        "def ifft(a, print_info=False, out_round_acc=6):\n",
        "    # bitreverse the input array to bring calculations in the for loops into the correct order\n",
        "    rev_a = bitrevorder(a)\n",
        "\n",
        "    n = int(np.log2(len(a)))\n",
        "\n",
        "    # Calculate the number of steps taken to compare it to the wanted running time of O(N * log(N))\n",
        "    # with N = len(a)\n",
        "    number_of_operations = 0\n",
        "    \n",
        "    for m  in range(1, n + 1):\n",
        "        if print_info:\n",
        "            print(\"m : \" + str(m))\n",
        "        for j in range(0, 2**(m - 1)):\n",
        "            e = round(np.exp(2 * np.pi * complex(0, 1) * j / (2**m)), 8)\n",
        "            if print_info:\n",
        "                print(\"j : \" + str(j))\n",
        "            for r in range(0, (2**n), (2**m)):\n",
        "                v = rev_a[r + j + 2**(m - 1)] * e\n",
        "\n",
        "                rev_a[r + j + 2**(m - 1)] = rev_a[r + j] - v\n",
        "                rev_a[r + j] = rev_a[r + j] + v\n",
        "\n",
        "                if print_info:\n",
        "                    print(\"r : \" + str(r))\n",
        "                    print(\"Calculation of: beta[\" + str(r + j) + \"]\")\n",
        "                    print(\"Calculation of: beta[\" + str(r + j + 2**(m - 1)) + \"]\")\n",
        "\n",
        "                # adapt the number of calculations\n",
        "                number_of_operations += 2\n",
        "\n",
        "    print(\"\\nN = \" + str(len(a)) + \" and Number of operations: (N * log_2(N)) = \" + str(number_of_operations) + \"\\n\")        \n",
        "    # transform complex array to real array\n",
        "    rev_a = np.round(np.asarray([round(i.real, out_round_acc) for i in rev_a]) / len(a), out_round_acc)\n",
        "\n",
        "    return rev_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a8jCOHtFDQ9",
        "colab_type": "code",
        "outputId": "0dffe0ba-7267-4700-fae7-e886c72bd449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ifft_array = ifft(fft_array, print_info=False)\n",
        "print(ifft_array)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "N = 16 and Number of operations: (N * log_2(N)) = 64\n",
            "\n",
            "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiYXf-sFIlxP",
        "colab_type": "text"
      },
      "source": [
        "<p>Since the array is the same as the original input into the FFT function, we know that the inverse FFT is working properly.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t82HlWPAI2xY",
        "colab_type": "text"
      },
      "source": [
        "# FFT2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmVcI14kK6F3",
        "colab_type": "text"
      },
      "source": [
        "<p>Again first of all define a random matrix and perform the np.fft.fft2() numpy FFT2D on it and save it for later comparison.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0E3nfceKt-F",
        "colab_type": "code",
        "outputId": "a2d0ae6c-b4f5-4fb4-8ba1-9e9850a10e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "matrix = np.array([[1, 2, 3, 4, 5, 6, 7, 8],\n",
        "                   [9, 10, 11, 12, 13, 14, 15, 16],\n",
        "                   [17, 18, 19, 20, 21, 22, 23, 24],\n",
        "                   [25, 26, 27, 28, 29, 30, 31, 32],\n",
        "                   [33, 34, 35, 36, 37, 38, 39, 40],\n",
        "                   [41, 42, 43, 44, 45, 46, 47, 48],\n",
        "                   [49, 50, 51, 52, 53, 54, 55, 56],\n",
        "                   [57, 58, 59, 60, 61, 62, 63, 64]])\n",
        "\n",
        "np_fft2d_matrix = np.fft.fft2(matrix)\n",
        "print(np_fft2d_matrix)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2080.  +0.j          -32. +77.254834j    -32. +32.j\n",
            "   -32. +13.254834j    -32.  +0.j          -32. -13.254834j\n",
            "   -32. -32.j          -32. -77.254834j  ]\n",
            " [-256.+618.03867197j    0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j        ]\n",
            " [-256.+256.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j        ]\n",
            " [-256.+106.03867197j    0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j        ]\n",
            " [-256.  +0.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j        ]\n",
            " [-256.-106.03867197j    0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j        ]\n",
            " [-256.-256.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j        ]\n",
            " [-256.-618.03867197j    0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j            0.  +0.j\n",
            "     0.  +0.j            0.  +0.j        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oddpkQ2_I7TY",
        "colab_type": "text"
      },
      "source": [
        "<p>The FFT2D as the FFT for matrices is often called, can be implemented by making use of the Cooley-Tukey algorithm. Therefore we just need to iterate first of all over the rows of the matrice and after that over the columns of it while performing an FFT for every row- or column-array.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab-9l_scI6vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################################################\n",
        "    # Input:\n",
        "    #     A:              Input matrix which will be transformed\n",
        "    #     print_info:     Boolean. If set to True all calculation steps will be printed out\n",
        "    #     out_round_acc:  Integer. Define rounding accuracy\n",
        "    # Output:\n",
        "    #     transformed:    FFT of the input matrix, same dimension as input matrix\n",
        "############################################################################################\n",
        "\n",
        "def fft2d(a, print_info=False, out_round_acc=6, print_ops=False):\n",
        "    rows, cols = a.shape\n",
        "    counter = 0\n",
        "    \n",
        "    # Calculate the number of steps taken to compare it to the wanted running time of O(N * log(N))\n",
        "    # with N = len(a)\n",
        "    number_of_operations = 0\n",
        "\n",
        "    for array in a:\n",
        "        # bitreverse the input array to bring calculations in the for loops into the correct order\n",
        "        rev_array = bitrevorder(array)\n",
        "        n = int(np.log2(len(array)))\n",
        "        \n",
        "        for m  in range(1, n + 1):\n",
        "            if print_info:\n",
        "                print(\"m : \" + str(m))\n",
        "            for j in range(0, 2**(m - 1)):\n",
        "                e = round(np.exp(-2 * np.pi * complex(0, 1) * j / (2**m)), 8)\n",
        "                if print_info:\n",
        "                    print(\"j : \" + str(j))\n",
        "                for r in range(0, (2**n), (2**m)):\n",
        "                    v = rev_array[r + j + 2**(m - 1)] * e\n",
        "\n",
        "                    rev_array[r + j + 2**(m - 1)] = rev_array[r + j] - v\n",
        "                    rev_array[r + j] = rev_array[r + j] + v\n",
        "\n",
        "                    if print_info:\n",
        "                        print(\"r : \" + str(r))\n",
        "                        print(\"Calculation of: beta[\" + str(r + j) + \"]\")\n",
        "                        print(\"Calculation of: beta[\" + str(r + j + 2**(m - 1)) + \"]\")\n",
        "                    \n",
        "                    # adapt the number of calculations  \n",
        "                    number_of_operations += 2\n",
        "\n",
        "        if counter == 0:     \n",
        "            transformed = np.asarray([np.round(i, out_round_acc) for i in rev_array])\n",
        "        else:\n",
        "            transformed = np.append(transformed, np.asarray([np.round(i, out_round_acc) for i in rev_array]), axis=0)\n",
        "        counter += 1\n",
        "    \n",
        "    if print_ops == True:\n",
        "        print(\"\\nN = \" + str(rows * cols) + \" and Number of operations: (N * log_2(N)) = \" + str(number_of_operations * 2) + \"\\n\")\n",
        "    \n",
        "    transformed = np.resize(transformed, (rows, cols))\n",
        "    # print(transformed)\n",
        "    \n",
        "    return transformed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufac4UVSIar_",
        "colab_type": "code",
        "outputId": "59663b5e-149c-4b2e-917f-e2b164107bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "fft2d_matrix = np.transpose(fft2d(np.transpose(fft2d(matrix, print_info=False)), print_info=False, print_ops=True))\n",
        "print(fft2d_matrix)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "N = 64 and Number of operations: (N * log_2(N)) = 384\n",
            "\n",
            "[[2080.  +0.j        -32. +77.254832j  -32. +32.j        -32. +13.254832j\n",
            "   -32.  +0.j        -32. -13.254832j  -32. -32.j        -32. -77.254832j]\n",
            " [-256.+618.038671j    0.  +0.j          0.  +0.j          0.  +0.j\n",
            "     0.  +0.j          0.  +0.j          0.  +0.j          0.  +0.j      ]\n",
            " [-256.+256.j          0.  +0.j          0.  +0.j          0.  +0.j\n",
            "     0.  +0.j          0.  +0.j          0.  +0.j          0.  +0.j      ]\n",
            " [-256.+106.038671j    0.  +0.j          0.  +0.j          0.  +0.j\n",
            "     0.  +0.j          0.  +0.j          0.  +0.j          0.  +0.j      ]\n",
            " [-256.  +0.j          0.  +0.j          0.  +0.j          0.  +0.j\n",
            "     0.  +0.j          0.  +0.j          0.  +0.j          0.  +0.j      ]\n",
            " [-256.-106.038671j    0.  +0.j          0.  +0.j          0.  +0.j\n",
            "     0.  +0.j          0.  +0.j          0.  +0.j          0.  +0.j      ]\n",
            " [-256.-256.j          0.  +0.j          0.  +0.j          0.  +0.j\n",
            "     0.  +0.j          0.  +0.j          0.  +0.j          0.  +0.j      ]\n",
            " [-256.-618.038671j    0.  +0.j          0.  +0.j          0.  +0.j\n",
            "     0.  +0.j          0.  +0.j          0.  +0.j          0.  +0.j      ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBUtS7pvLx2w",
        "colab_type": "text"
      },
      "source": [
        "<p>Again compare the results of the numpy result with the self-implemented one.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xIrnj3EKn9q",
        "colab_type": "code",
        "outputId": "c00caa1a-02de-4580-95a0-0e04f13b27b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(np.isclose(np_fft2d_matrix, fft2d_matrix, atol=1e-8, rtol=1e-5))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True]\n",
            " [ True  True  True  True  True  True  True  True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tprQePxCMNSJ",
        "colab_type": "text"
      },
      "source": [
        "<p>Since the comparison only result true values for all elementwise comparison we can conclude that the self-implemented FFT2D is working fine.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xMsL1pDNNFx",
        "colab_type": "text"
      },
      "source": [
        "<p>Now the last thing to do is to implement and test the inverse FFT2D, which can be analogously made out of the FFT2D like the iFFT vor the array case.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0drj_j7MIfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################################################\n",
        "    # Input:\n",
        "    #     A:              Input matrix which will be transformed\n",
        "    #     print_info:     Boolean. If set to True all calculation steps will be printed out\n",
        "    #     out_round_acc:  Integer. Define rounding accuracy\n",
        "    # Output:\n",
        "    #     transformed:    FFT of the input matrix, same dimension as input matrix\n",
        "############################################################################################\n",
        "\n",
        "def ifft2d(a, print_info=False, out_round_acc=6, first=True, print_ops=False):\n",
        "    rows, cols = a.shape\n",
        "    counter = 0\n",
        "    \n",
        "    # Calculate the number of steps taken to compare it to the wanted running time of O(N * log(N))\n",
        "    # with N = len(a)\n",
        "    number_of_operations = 0\n",
        "\n",
        "    for array in a:\n",
        "        # bitreverse the input array to bring calculations in the for loops into the correct order\n",
        "        rev_array = bitrevorder(array)\n",
        "        n = int(np.log2(len(array)))\n",
        "        \n",
        "        for m  in range(1, n + 1):\n",
        "            if print_info:\n",
        "                print(\"m : \" + str(m))\n",
        "            for j in range(0, 2**(m - 1)):\n",
        "                e = round(np.exp(2 * np.pi * complex(0, 1) * j / (2**m)), 8)\n",
        "                if print_info:\n",
        "                    print(\"j : \" + str(j))\n",
        "                for r in range(0, (2**n), (2**m)):\n",
        "                    v = rev_array[r + j + 2**(m - 1)] * e\n",
        "\n",
        "                    rev_array[r + j + 2**(m - 1)] = rev_array[r + j] - v\n",
        "                    rev_array[r + j] = rev_array[r + j] + v\n",
        "\n",
        "                    if print_info:\n",
        "                        print(\"r : \" + str(r))\n",
        "                        print(\"Calculation of: beta[\" + str(r + j) + \"]\")\n",
        "                        print(\"Calculation of: beta[\" + str(r + j + 2**(m - 1)) + \"]\")\n",
        "                    \n",
        "                    # adapt the number of calculations  \n",
        "                    number_of_operations += 2\n",
        "\n",
        "        if first == True:\n",
        "            if counter == 0:     \n",
        "                transformed = np.round(np.asarray([np.round(i, out_round_acc) for i in rev_array]) / 8, out_round_acc)\n",
        "                if print_info:\n",
        "                    print(transformed)\n",
        "            else:\n",
        "                if print_info:\n",
        "                    print(np.round(np.asarray([np.round(i, out_round_acc) for i in rev_array]) / 8, out_round_acc))\n",
        "                transformed = np.append(transformed, np.round(np.asarray([np.round(i, out_round_acc) for i in rev_array]) / 8, out_round_acc), axis=0)\n",
        "        else:\n",
        "            if counter == 0:     \n",
        "                transformed = np.round(np.asarray([np.round(i.real, out_round_acc) for i in rev_array]) / 8, out_round_acc)\n",
        "                if print_info:\n",
        "                    print(transformed)\n",
        "            else:\n",
        "                if print_info:\n",
        "                    print(np.round(np.asarray([np.round(i.real, out_round_acc) for i in rev_array]) / 8, out_round_acc))\n",
        "                transformed = np.append(transformed, np.round(np.asarray([np.round(i.real, out_round_acc) for i in rev_array]) / 8, out_round_acc), axis=0)\n",
        "        \n",
        "        counter += 1\n",
        "\n",
        "    if print_ops == True:\n",
        "        print(\"\\nN = \" + str(rows * cols) + \" and Number of operations: (N * log_2(N)) = \" + str(number_of_operations * 2) + \"\\n\")\n",
        "    \n",
        "    transformed = np.resize(transformed, (rows, cols))\n",
        "    # print(transformed)\n",
        "    \n",
        "    return transformed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqEBxSIUNL61",
        "colab_type": "code",
        "outputId": "1dd105db-7ea2-4d56-9f8d-7c7608e5d970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ifft2d_matrix = ifft2d(np.transpose(ifft2d(np.transpose(my_fft2d), print_info=False)), print_info=False, first=False, print_ops=True)\n",
        "print(ifft2d_matrix)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "N = 64 and Number of operations: (N * log_2(N)) = 384\n",
            "\n",
            "[[ 1.  2.  3.  4.  5.  6.  7.  8.]\n",
            " [ 9. 10. 11. 12. 13. 14. 15. 16.]\n",
            " [17. 18. 19. 20. 21. 22. 23. 24.]\n",
            " [25. 26. 27. 28. 29. 30. 31. 32.]\n",
            " [33. 34. 35. 36. 37. 38. 39. 40.]\n",
            " [41. 42. 43. 44. 45. 46. 47. 48.]\n",
            " [49. 50. 51. 52. 53. 54. 55. 56.]\n",
            " [57. 58. 59. 60. 61. 62. 63. 64.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEVvkfKKOPcC",
        "colab_type": "text"
      },
      "source": [
        "<p>Well, it looks like the iFFT2D is working as good as hoped.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhQ90e7pOZYC",
        "colab_type": "text"
      },
      "source": [
        "### FFT2D test on MNIST digit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np-CzGWrN180",
        "colab_type": "code",
        "outputId": "6fbb0535-0d28-475a-b7c2-4bf0b95270aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# save an image to work with\n",
        "img = X_train[0]\n",
        "print(img.shape)\n",
        "\n",
        "show_img(img)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-5XJpIhSGOR",
        "colab_type": "text"
      },
      "source": [
        "<p>To work with the image in the self-implemented code, we need to pad it so that the width and height of the image are can be expressed through 2^n, with n > 0 an integer.</p>\n",
        "<p>The below written function just provides periodic padding for the case of the image width and height equal to 2^n - 4.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjFSkkRvPu5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def periodic_padding(img, pad=2):\n",
        "    img_padded = np.zeros((img.shape[0] + pad * 2, img.shape[1] + pad * 2))\n",
        "    if pad % 2 == 0:\n",
        "        # c = int(pad / 2)\n",
        "        # img_padded[c:-c, c:-c] = img\n",
        "        img_padded[pad:-pad, pad:-pad] = img\n",
        "    else:\n",
        "        return \"pad must be even\"\n",
        "\n",
        "    if img_padded.shape[0] % 8 != 0 or img_padded.shape[1] % 8 != 0:\n",
        "        return \"padded image dimension must be devisble by 8\"\n",
        "\n",
        "    n = img_padded.shape[0]\n",
        "    m = img.shape[0] - 1\n",
        "\n",
        "    #### only pad == 2 case ####\n",
        "\n",
        "    # handling corners\n",
        "    img_padded[0, 0] = img[m - 1, m - 1]\n",
        "    img_padded[0, 1] = img[m - 1, m]\n",
        "    img_padded[1, 0] = img[m, m - 1]\n",
        "    img_padded[1, 1] = img[m, m]\n",
        "\n",
        "    img_padded[0, n - pad] = img[m - 1, 0]\n",
        "    img_padded[0, n - pad + 1] = img[m - 1, 1]\n",
        "    img_padded[1, n - pad] = img[m, 0]\n",
        "    img_padded[1, n - pad + 1] = img[m, 1]\n",
        "\n",
        "    img_padded[n - pad, 0] = img[0, m - 1]\n",
        "    img_padded[n - pad + 1, 0] = img[1, m - 1]\n",
        "    img_padded[n - pad, 1] = img[0, m]\n",
        "    img_padded[n - pad + 1, 1] = img[1, m]\n",
        "\n",
        "    img_padded[n - pad, n - pad] = img[0, 0]\n",
        "    img_padded[n - pad, n - pad + 1] = img[0, 1]\n",
        "    img_padded[n - pad + 1, n - pad] = img[1, 0]\n",
        "    img_padded[n - pad + 1, n - pad + 1] = img[1, 1]\n",
        "\n",
        "    for i in range(pad, n - pad):\n",
        "        img_padded[i, 0] = img_padded[i, n - 2*pad]\n",
        "        img_padded[i, 1] = img_padded[i, n - 2*pad + 1]\n",
        "        img_padded[0, i] = img_padded[n - 2*pad, i]\n",
        "        img_padded[1, i] = img_padded[n - 2*pad + 1, i]\n",
        "        img_padded[i, n - pad] = img_padded[i, pad + 1]\n",
        "        img_padded[i, n - pad + 1] = img_padded[i, pad + 0]\n",
        "        img_padded[n - pad, i] = img_padded[pad + 0, i]\n",
        "        img_padded[n - pad + 1, i] = img_padded[pad + 1, i]\n",
        "\n",
        "    return img_padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvEixH8JOvyA",
        "colab_type": "code",
        "outputId": "c361e227-31a2-45b4-9861-90799d4ce6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "import time\n",
        "\n",
        "padded_img = periodic_padding(img)\n",
        "# show_img(padded_img, size=32)\n",
        "\n",
        "# in numpy it would not be necessary to input the padded version because it could\n",
        "# handle all kinds of shape\n",
        "# but to compare it better we will give it the padded image\n",
        "start_time = time.time()\n",
        "np_fft2d_img = np.fft.fft2(padded_img)\n",
        "end_time = time.time()\n",
        "print(\"The Numpy FFT2D took \" + str(end_time - start_time) + \" ms.\")\n",
        "show_img(np.real(np_fft2d_img), size=32)\n",
        "\n",
        "# do not forget to run the fft2d twice in the self-implemented version\n",
        "start_time = time.time()\n",
        "fft2d_img = np.transpose(fft2d(np.transpose(fft2d(padded_img))))\n",
        "end_time = time.time()\n",
        "print(\"The self-implemented FFT2D took \" + str(end_time - start_time) + \" ms.\")\n",
        "show_img(np.real(fft2d_img), size=32)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Numpy FFT2D took 0.0003161430358886719 ms.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH7X5fmnWaPwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The self-implemented FFT2D took 0.07830262184143066 ms.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH7X5fmnWaPwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMu9x7mJVbvW",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "<p>Even though the self-implemented Fourier Transform using the Cooley-Tukey algorithm is working well, we can still see that it is not even close to be optimized well for fast calculations, which is especially caused by the slow speed of the Python environment and the algorithm itself. Nowadays exist even faster algorithms than the most basic one by Cooley-Tukey.</p>"
      ]
    }
  ]
}